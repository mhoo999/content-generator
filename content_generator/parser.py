"""
ì—‘ì…€/CSV íŒŒì¼ íŒŒì‹± ëª¨ë“ˆ
"""

import pandas as pd
import requests
import re
from pathlib import Path
from typing import Dict, List, Optional
from io import BytesIO


class CourseDataParser:
    """ê³¼ì • ë°ì´í„° íŒŒì„œ"""

    # ì»¬ëŸ¼ ë§¤í•‘ (ì—‘ì…€ ì»¬ëŸ¼ëª… â†’ ë‚´ë¶€ í•„ë“œëª…)
    COLUMN_MAPPING = {
        'ê³¼ì •ëª…': 'subject',
        'ì°¨ì‹œ': 'lesson_order',
        'ì±•í„°êµ¬ë¶„': 'chapter_number',
        'ì±•í„°ëª…': 'chapter_name',
        'ê°•ì˜ ìˆ˜': 'lecture_count',
        'ì°¨ì‹œë²ˆí˜¸': 'lesson_number',
        'ì°¨ì‹œëª…': 'lesson_title',
        'í•™ìŠµìí˜ì´ì§€ ë…¸ì¶œ ì°¨ì‹œëª…': 'lesson_display_title',
        'ê°•ì˜ì˜ìƒ(mp4) ë§í¬': 'video_url',
        'ë‹¤ìš´ë¡œë“œ(zip) ë§í¬': 'download_url',
    }

    REQUIRED_COLUMNS = ['ê³¼ì •ëª…', 'ì°¨ì‹œë²ˆí˜¸', 'ì°¨ì‹œëª…', 'ê°•ì˜ì˜ìƒ(mp4) ë§í¬']

    def __init__(self, file_path: str):
        """
        Args:
            file_path: ì—‘ì…€/CSV íŒŒì¼ ê²½ë¡œ ë˜ëŠ” êµ¬ê¸€ ì‹œíŠ¸ URL
        """
        self.file_path_or_url = file_path
        self.is_url = self._is_url(file_path)
        self.file_path = None if self.is_url else Path(file_path)
        self.df: Optional[pd.DataFrame] = None
        self.course_code: Optional[str] = None

    @staticmethod
    def _is_url(path: str) -> bool:
        """URLì¸ì§€ í™•ì¸"""
        return path.startswith('http://') or path.startswith('https://')

    @staticmethod
    def _convert_google_sheets_url(url: str) -> str:
        """
        êµ¬ê¸€ ì‹œíŠ¸ URLì„ CSV export URLë¡œ ë³€í™˜

        ì…ë ¥ ì˜ˆì‹œ:
        - https://docs.google.com/spreadsheets/d/SHEET_ID/edit#gid=0
        - https://docs.google.com/spreadsheets/d/SHEET_ID/edit?usp=sharing

        ì¶œë ¥:
        - https://docs.google.com/spreadsheets/d/SHEET_ID/export?format=csv&gid=0
        """
        # SHEET_ID ì¶”ì¶œ
        match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', url)
        if not match:
            return url  # êµ¬ê¸€ ì‹œíŠ¸ê°€ ì•„ë‹ˆë©´ ì›ë³¸ ë°˜í™˜

        sheet_id = match.group(1)

        # GID ì¶”ì¶œ (ì‹œíŠ¸ íƒ­ ë²ˆí˜¸, ê¸°ë³¸ê°’ 0)
        gid_match = re.search(r'[#&]gid=(\d+)', url)
        gid = gid_match.group(1) if gid_match else '0'

        return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}"

    def parse(self) -> Dict:
        """
        íŒŒì¼ ë˜ëŠ” URLì„ íŒŒì‹±í•˜ì—¬ ê³¼ì • ë°ì´í„° ë°˜í™˜

        Returns:
            {
                'course_code': '25ctvibec',
                'subject': 'ê³¼ì •ëª…',
                'chapters': [
                    {
                        'number': 1,
                        'name': 'Part.1 ...',
                        'lessons': [...]
                    }
                ],
                'lessons': [...],
                'total_lessons': 22
            }
        """
        # ë°ì´í„° ì½ê¸°
        if self.is_url:
            self._load_from_url()
        else:
            self._load_from_file()

        # ì»¬ëŸ¼ ê²€ì¦
        self._validate_columns()

        # ë°ì´í„° ì •ë¦¬
        self._clean_data()

        # íŒŒì‹±
        course_data = self._parse_course_data()

        return course_data

    def _load_from_url(self):
        """URLì—ì„œ ë°ì´í„° ë¡œë“œ"""
        url = self.file_path_or_url

        # êµ¬ê¸€ ì‹œíŠ¸ URLì´ë©´ CSV export URLë¡œ ë³€í™˜
        if 'docs.google.com/spreadsheets' in url:
            url = self._convert_google_sheets_url(url)
            print(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

        # URLì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
        except requests.RequestException as e:
            raise ValueError(f"URLì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

        # CSVë¡œ íŒŒì‹±
        try:
            self.df = pd.read_csv(BytesIO(response.content))
        except Exception as e:
            raise ValueError(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")

    def _load_from_file(self):
        """íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        if self.file_path.suffix == '.xlsx':
            self.df = pd.read_excel(self.file_path)
        elif self.file_path.suffix == '.csv':
            self.df = pd.read_csv(self.file_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {self.file_path.suffix}")

    def _validate_columns(self):
        """í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸"""
        missing_columns = []
        for col in self.REQUIRED_COLUMNS:
            if col not in self.df.columns:
                missing_columns.append(col)

        if missing_columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing_columns)}")

    def _clean_data(self):
        """ë°ì´í„° ì •ë¦¬ (ë¹ˆ ì…€ ì±„ìš°ê¸°)"""
        # ê³¼ì •ëª…: ì²« ë²ˆì§¸ í–‰ ê°’ìœ¼ë¡œ ëª¨ë‘ ì±„ìš°ê¸°
        if 'ê³¼ì •ëª…' in self.df.columns:
            first_subject = self.df['ê³¼ì •ëª…'].iloc[0]
            self.df['ê³¼ì •ëª…'] = self.df['ê³¼ì •ëª…'].fillna(first_subject)

        # ì±•í„° ì •ë³´: ì´ì „ í–‰ ê°’ìœ¼ë¡œ ì±„ìš°ê¸° (forward fill)
        if 'ì±•í„°êµ¬ë¶„' in self.df.columns:
            self.df['ì±•í„°êµ¬ë¶„'] = self.df['ì±•í„°êµ¬ë¶„'].ffill()
        if 'ì±•í„°ëª…' in self.df.columns:
            self.df['ì±•í„°ëª…'] = self.df['ì±•í„°ëª…'].ffill()

        # NaNì„ Noneìœ¼ë¡œ ë³€í™˜
        self.df = self.df.where(pd.notnull(self.df), None)

    def _parse_course_data(self) -> Dict:
        """ê³¼ì • ë°ì´í„° íŒŒì‹±"""
        # ê³¼ì •ëª… ì¶”ì¶œ
        subject = self.df['ê³¼ì •ëª…'].iloc[0]

        # ì°¨ì‹œ ë°ì´í„° ì¶”ì¶œ
        lessons = []
        chapters = []
        current_chapter = None

        for idx, row in self.df.iterrows():
            # ì°¨ì‹œ ë°ì´í„°
            lesson = {
                'index': int(row['ì°¨ì‹œë²ˆí˜¸']) if pd.notna(row['ì°¨ì‹œë²ˆí˜¸']) else idx + 1,
                'number': f"{int(row['ì°¨ì‹œë²ˆí˜¸']):02d}" if pd.notna(row['ì°¨ì‹œë²ˆí˜¸']) else f"{idx + 1:02d}",
                'title': row['ì°¨ì‹œëª…'],
                'video_url': self._normalize_url(row['ê°•ì˜ì˜ìƒ(mp4) ë§í¬']),
                'download_url': self._normalize_url(row.get('ë‹¤ìš´ë¡œë“œ(zip) ë§í¬')),
            }
            lessons.append(lesson)

            # ì±•í„° ì •ë³´ (ì±•í„°êµ¬ë¶„ì´ ë³€ê²½ë  ë•Œ)
            if 'ì±•í„°êµ¬ë¶„' in row and pd.notna(row['ì±•í„°êµ¬ë¶„']):
                chapter_num = int(row['ì±•í„°êµ¬ë¶„'])
                if current_chapter is None or current_chapter['number'] != chapter_num:
                    current_chapter = {
                        'number': chapter_num,
                        'name': row.get('ì±•í„°ëª…', f'Part.{chapter_num}'),
                        'lesson_start': lesson['index'],
                        'lessons': []
                    }
                    chapters.append(current_chapter)

            if current_chapter:
                current_chapter['lessons'].append(lesson['number'])

        # ê³¼ì • ì½”ë“œ ì¶”ì¶œ (ê°•ì˜ì˜ìƒ ë§í¬ì—ì„œ)
        if lessons:
            video_url = lessons[0]['video_url']
            # ì˜ˆ: https://cdn-it.livestudy.com/mov/2025/25ctvibec/25ctvibec_01.mp4
            # â†’ 25ctvibec
            parts = video_url.split('/')
            for i, part in enumerate(parts):
                if part.isdigit() and len(part) == 4:  # ë…„ë„ (2025)
                    if i + 1 < len(parts):
                        self.course_code = parts[i + 1]
                        break

        return {
            'course_code': self.course_code,
            'subject': subject,
            'chapters': chapters,
            'lessons': lessons,
            'total_lessons': len(lessons)
        }

    def _normalize_url(self, url: Optional[str]) -> Optional[str]:
        """URL ì •ê·œí™” (https:// ì¶”ê°€)"""
        if not url:
            return None

        url = str(url).strip()
        if url.startswith('/'):
            return f"https:{url}"
        elif not url.startswith('http'):
            return f"https://{url}"
        return url


def parse_course_file(file_path: str) -> Dict:
    """
    ê³¼ì • íŒŒì¼ íŒŒì‹± (í—¬í¼ í•¨ìˆ˜)

    Args:
        file_path: ì—‘ì…€ ë˜ëŠ” CSV íŒŒì¼ ê²½ë¡œ

    Returns:
        íŒŒì‹±ëœ ê³¼ì • ë°ì´í„°
    """
    parser = CourseDataParser(file_path)
    return parser.parse()
